{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komal-shahzada/python/blob/main/fyp__Speech_Emotion_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6aBe2SI767M",
        "outputId": "deeda954-ae08-407e-c39b-b56b883e678a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: resampy in /usr/local/lib/python3.12/dist-packages (0.4.3)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
            "Requirement already satisfied: opendatasets in /usr/local/lib/python3.12/dist-packages (0.1.22)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from resampy) (2.0.2)\n",
            "Requirement already satisfied: numba>=0.53 in /usr/local/lib/python3.12/dist-packages (from resampy) (0.60.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.5.3)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.0.0)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.15.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.1.2)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.12.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.123.10)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.14.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<=2.12.3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.12.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.9)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.50.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (from opendatasets) (1.7.4.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from opendatasets) (8.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.53->resampy) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.3)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (4.5.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->librosa) (2.0.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (6.3.0)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (3.4.4)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (5.29.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.23)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install resampy librosa gradio opendatasets\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import tqdm\n",
        "import opendatasets as od\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxekKw2s7-nf",
        "outputId": "6d95d32e-f597-45a1-a340-5ee97492ffff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping, found downloaded files in \"./ravdess-emotional-speech-audio\" (use force=True to force download)\n"
          ]
        }
      ],
      "source": [
        "od.download(\"https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SjhBdndZ8-yA"
      },
      "outputs": [],
      "source": [
        "def extract_features(file_path):\n",
        "    # 2.5 seconds fixed duration  to mach or record live  audio\n",
        "    data, sample_rate = librosa.load(file_path, res_type='kaiser_fast', duration=2.5, sr=22050, offset=0.5)\n",
        "\n",
        "    # Padding:  if audio is short add silence to complete it\n",
        "    if len(data) < 55125:\n",
        "        data = np.pad(data, (0, 55125 - len(data)), 'constant')\n",
        "\n",
        "    mfccs = librosa.feature.mfcc(y=data, sr=sample_rate, n_mfcc=40)\n",
        "    return np.mean(mfccs.T, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-X4gmol9AQz",
        "outputId": "aa4e8bcc-1b52-4b93-ce86-a766d5dc4e2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching for files and extracting features.. ...\n",
            "Success! 2880 files is processed.\n"
          ]
        }
      ],
      "source": [
        "X, y = [], []\n",
        "data_path = 'ravdess-emotional-speech-audio'\n",
        "\n",
        "print(\"Searching for files and extracting features.. ...\")\n",
        "for root, dirs, files in os.walk(data_path):\n",
        "    for file in files:\n",
        "        if file.endswith('.wav'):\n",
        "            try:\n",
        "                parts = file.split(\"-\")\n",
        "                emotion = int(parts[2]) # in RAVDESS  3rd part is emotion\n",
        "                feature = extract_features(os.path.join(root, file))\n",
        "                X.append(feature)\n",
        "                y.append(emotion)\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "print(f\"Success! {len(X)} files is processed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnpB6g0f9EHd",
        "outputId": "ceedfb4c-c518-4e9a-889b-f14bbc613e2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data is ready for training!\n"
          ]
        }
      ],
      "source": [
        "lb = LabelEncoder()\n",
        "y_final = to_categorical(lb.fit_transform(y))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_final, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Model ke liye shape set karna\n",
        "X_train = np.expand_dims(X_train, axis=2)\n",
        "X_test = np.expand_dims(X_test, axis=2)\n",
        "print(\"Data is ready for training!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DK6vECE9MdX",
        "outputId": "7057b027-8682-4d64-deaf-f7c0914f1d50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model = Sequential([\n",
        "    Conv1D(256, 8, padding='same', activation='relu', input_shape=(40, 1)),\n",
        "    BatchNormalization(),\n",
        "    Conv1D(128, 8, padding='same', activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.2),\n",
        "    MaxPooling1D(pool_size=8),\n",
        "\n",
        "    Conv1D(64, 8, padding='same', activation='relu'),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(y_final.shape[1], activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ra3Xx-v0Gi5n",
        "outputId": "c8a00b55-6fab-467b-bd72-78313232f6c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://3dfb05b2616b3de493.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "# 1. Emotions Map (same as in training)\n",
        "emotions_map = {1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fearful', 7:'disgust', 8:'surprised'}\n",
        "\n",
        "def predict_emotion_live(audio_path):\n",
        "    if audio_path is None:\n",
        "        return \"Please record or upload your voice!\"\n",
        "\n",
        "    try:\n",
        "        # 2. Audio Processing (Settings matching your training)\n",
        "        data, sr = librosa.load(audio_path, sr=22050, duration=2.5)\n",
        "        data = librosa.util.normalize(data)\n",
        "        data, _ = librosa.effects.trim(data, top_db=30)\n",
        "\n",
        "        # 3. Padding logic\n",
        "        if len(data) < 55125:\n",
        "            data = np.pad(data, (0, 55125 - len(data)), 'constant')\n",
        "\n",
        "        # 4. Feature Extraction\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sr, n_mfcc=40).T, axis=0)\n",
        "\n",
        "        # 5. Scaling & Reshaping (Using your trained scaler and model)\n",
        "        scaled = scaler.transform(mfccs.reshape(1, -1))\n",
        "        reshaped = np.expand_dims(scaled, axis=2)\n",
        "\n",
        "        # 6. Prediction\n",
        "        predictions = model.predict(reshaped, verbose=0)[0]\n",
        "\n",
        "        # Scores dictionary banana\n",
        "        results = {}\n",
        "        for i, prob in enumerate(predictions):\n",
        "            emotion_label = lb.inverse_transform([i])[0]\n",
        "            emotion_name = emotions_map[emotion_label]\n",
        "            results[emotion_name.upper()] = float(prob)\n",
        "\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\"Error\": str(e)}\n",
        "\n",
        "# 7. Dashboard Launch (Updated settings for faster loading)\n",
        "iface = gr.Interface(\n",
        "    fn=predict_emotion_live,\n",
        "    inputs=gr.Audio(sources=[\"microphone\", \"upload\"], type=\"filepath\", label=\"Record or Upload Audio\"),\n",
        "    outputs=gr.Label(num_top_classes=3, label=\"Top Predictions\"),\n",
        "    title=\"ðŸŽ™ï¸ Komal's Speech Emotion Recognition System\",\n",
        "    description=\"Speak clearly to see real-time emotion analysis.\",\n",
        "    theme=\"default\"\n",
        ")\n",
        "\n",
        "# inline=False for that it never stuck or open in new tab\n",
        "iface.launch(share=True, inline=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "7XuU5nLrISNg",
        "outputId": "42d0ebf9-147e-4f51-ff6b-eeb151d3e760"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Click on Recording button ...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2615223474.py:14: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  data, sr = librosa.load(audio_path, sr=22050, duration=2.5)\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Model Prediction ---\n",
            "NEUTRAL: 12.1%\n",
            "CALM: 13.3%\n",
            "HAPPY: 12.0%\n",
            "SAD: 12.6%\n",
            "ANGRY: 13.0%\n",
            "FEARFUL: 12.0%\n",
            "DISGUST: 12.1%\n",
            "SURPRISED: 12.9%\n"
          ]
        }
      ],
      "source": [
        "from google.colab import output\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "# Ye JavaScript code get direct acess from browser\n",
        "def record_audio_colab():\n",
        "    js = \"\"\"\n",
        "    async function recordAudio() {\n",
        "      const div = document.createElement('div');\n",
        "      const button = document.createElement('button');\n",
        "      button.textContent = 'Click to Record (5 Seconds)';\n",
        "      div.appendChild(button);\n",
        "      document.body.appendChild(div);\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({audio:true});\n",
        "      const recorder = new MediaRecorder(stream);\n",
        "      const chunks = [];\n",
        "      recorder.ondataavailable = e => chunks.push(e.data);\n",
        "      recorder.start();\n",
        "      await new Promise(resolve => button.onclick = resolve);\n",
        "      button.textContent = 'Recording... Wait';\n",
        "      await new Promise(r => setTimeout(r, 5000));\n",
        "      recorder.stop();\n",
        "      await new Promise(r => recorder.onstop = r);\n",
        "      const blob = new Blob(chunks);\n",
        "      const reader = new FileReader();\n",
        "      reader.readAsDataURL(blob);\n",
        "      await new Promise(r => reader.onloadend = r);\n",
        "      return reader.result;\n",
        "    }\n",
        "    \"\"\"\n",
        "    display(eval_js(js))\n",
        "    audio_data = eval_js('recordAudio()')\n",
        "    return b64decode(audio_data.split(',')[1])\n",
        "\n",
        "# let start Recording\n",
        "print(\"Click on Recording button ...\")\n",
        "audio_bytes = record_audio_colab()\n",
        "with open(\"test_mic.wav\", \"wb\") as f:\n",
        "    f.write(audio_bytes)\n",
        "\n",
        "# view Prediction result\n",
        "result = predict_emotion_live(\"test_mic.wav\")\n",
        "print(\"\\n--- Model Prediction ---\")\n",
        "for emotion, prob in result.items():\n",
        "    print(f\"{emotion}: {prob*100:.1f}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyP1EKVBrmoiown7W0FqmhZo",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}